{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "data = arff.loadarff('C:/Users/Alex JS/Autism-Adult-Data.arff')\n",
    "df = pd.DataFrame(data[0])   # convert to pandas df\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A1_Score'] = df['A1_Score'].astype(int)  # Convert column data types\n",
    "df['A2_Score'] = df['A2_Score'].astype(int)\n",
    "df['A3_Score'] = df['A3_Score'].astype(int)\n",
    "df['A4_Score'] = df['A4_Score'].astype(int)\n",
    "df['A5_Score'] = df['A5_Score'].astype(int)\n",
    "df['A6_Score'] = df['A6_Score'].astype(int)\n",
    "df['A7_Score'] = df['A7_Score'].astype(int)\n",
    "df['A8_Score'] = df['A8_Score'].astype(int)\n",
    "df['A9_Score'] = df['A9_Score'].astype(int)\n",
    "df['A10_Score'] = df['A10_Score'].astype(int)\n",
    "df['result'] = df['result'].astype(int)\n",
    "\n",
    "df['gender'] = df['gender'].str.decode('utf-8')\n",
    "df['ethnicity'] = df['ethnicity'].str.decode('utf-8')\n",
    "df['jundice'] = df['jundice'].str.decode('utf-8')\n",
    "df['austim'] = df['austim'].str.decode('utf-8')\n",
    "df['contry_of_res'] = df['contry_of_res'].str.decode('utf-8')\n",
    "df['used_app_before'] = df['used_app_before'].str.decode('utf-8')\n",
    "df['age_desc'] = df['age_desc'].str.decode('utf-8')\n",
    "df['relation'] = df['relation'].str.decode('utf-8')\n",
    "df['Class/ASD'] = df['Class/ASD'].str.decode('utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()   # check datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"?\",np.nan, inplace=True)   # replace ? with null\n",
    "missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "percent_missing = (df.isnull().sum() / df.isnull().count()*100).sort_values(ascending=False)\n",
    "m_data = pd.concat([missing_data, percent_missing], axis=1,keys=['Total', 'Percent'])\n",
    "m_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.max(), df.age.min()    # max and min age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.age != 383]     # remove person aged 383."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.max(), df.age.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna((df['age'].mean()),inplace=True)  # replace null age fields with average age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "percent_missing = (df.isnull().sum() / df.isnull().count()*100).sort_values(ascending=False) # calculate total and percentage missing data\n",
    "m_data = pd.concat([missing_data, percent_missing], axis=1,keys=['Total', 'Percent'])\n",
    "m_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.columns = map(lambda x: x.strip().lower(), df.columns) # convert columns to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.jundice = df.jundice.apply(lambda x: 0 if x == 'no' else 1) # Covert yes/no into 1/0\n",
    "df.austim = df.austim.apply(lambda x: 0 if x == 'no' else 1)\n",
    "df.used_app_before = df.used_app_before.apply(lambda x: 0 if x == 'no' else 1)\n",
    "df.rename(columns={'class/asd': 'classification'}, inplace=True)\n",
    "df.gender = df.gender.apply(lambda x: 0 if x == 'f' else 1)   # make Females 0 Males 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.classification = df.classification.apply(lambda x: 0 if x == 'NO' else 1) # change autism class NO - 0, Yes - 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning categorical data \n",
    "df.contry_of_res = df.contry_of_res.str.replace(\"'\", \"\")\n",
    "df.contry_of_res = df.contry_of_res.str.strip()\n",
    "df.relation = df.relation.str.replace(\"'\", \"\")\n",
    "df.relation = df.relation.str.strip()\n",
    "df.ethnicity = df.ethnicity.str.replace(\"'\", \"\")\n",
    "df.ethnicity = df.ethnicity.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender[df.classification == 0].value_counts()  ## males (1) vs females (0) without ASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender[df.classification == 1].value_counts()  # Males(1) vs females(0) with ASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ethnicity[df.classification == 0].value_counts().plot(kind='bar')  # bar plot of ethnicities without ASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ethnicity[df.classification == 1].value_counts().plot(kind='bar')   # Bar plot of ethnicities with ASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "title = 'Countries with most people classified not having ASD'\n",
    "df.contry_of_res[df.classification == 0].value_counts().plot(kind='bar', ax=ax, title=title) # bar plot of number of those in each country without asd\n",
    "ax.set_xlim(1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "title = 'Countries with most people classified as having ASD'\n",
    "\n",
    "df.contry_of_res[df.classification == 1].value_counts().plot(kind='bar', ax=ax, title=title) #bar plot showing number of people in countries with ASD\n",
    "ax.set_xlim(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('relation', axis=1, inplace=True)   # drop categorical data\n",
    "df.drop('age_desc', axis=1, inplace=True)\n",
    "df.drop('contry_of_res', axis=1, inplace=True)\n",
    "df.drop('ethnicity', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEnc = LabelEncoder()\n",
    "columns = [ 'gender', 'age', 'classification', 'jundice']\n",
    "for cols in columns:\n",
    "    df[cols] = labelEnc.fit_transform(df[cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['classification'], axis = 1)\n",
    "y = df['classification']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5)   # split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []    # classifiers used\n",
    "classifiers.append(('Logistic Regression', LogisticRegressionCV(cv=10, max_iter=2000)))\n",
    "classifiers.append(('Decision Trees', DecisionTreeClassifier()))\n",
    "classifiers.append(('Random Forests', RandomForestClassifier(n_estimators=5)))\n",
    "classifiers.append(('K Neighbours', KNeighborsClassifier(n_neighbors=5)))\n",
    "classifiers.append(('SVM', SVC(kernel='linear')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"No\", \"Yes\"]\n",
    "results = []\n",
    "for name, classifier in classifiers:  # loop through the classifiers\n",
    "    kfold = model_selection.KFold(n_splits=5)      # k fold with 5 splits\n",
    "    result = model_selection.cross_val_score(classifier, x, y, cv=kfold, scoring='accuracy') # get cross validation score with k fold for each classifier\n",
    "    classifier.fit(x_train, y_train)   # fit the data to classifier\n",
    "    pred = classifier.predict(x_test)   # make a predicition\n",
    "    acc_score = accuracy_score(y_test, pred)   # get the accuracy score\n",
    "    results.append(result)  # add cross val result to results list.\n",
    "    print(name)\n",
    "    print('Accuracy Score: ', acc_score)   # print accuracy score\n",
    "    print('Recall Score: ', recall_score(y_test, pred))  # print and get recall score\n",
    "    print('F1 Score: ', f1_score(y_test, pred))  # print and get f1 score\n",
    "    print(classification_report(y_test, pred, target_names=classes)) #  print and get classification report\n",
    "    print(confusion_matrix(y_test, pred)) # print and get confusion matrix\n",
    "    print(\"------------------------------------------------------------------------------\") # seperator\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['LR', 'DT', 'RF', 'KNN', 'SVM']\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Classifier comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)   # plot results\n",
    "ax.set_xticklabels(names)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "parameters = {\n",
    "    'C': [0.1,0.3,0.4,0.6,1.1,1.2,1.3,1.4, 1.9],\n",
    "    'gamma' : [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n",
    "}\n",
    "\n",
    "gsc = GridSearchCV(svc, param_grid = parameters, scoring = 'accuracy', cv= 10)\n",
    "gsc.fit(x_train, y_train)\n",
    "gsc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2 = SVC(C = 1.1, gamma = 0.1, kernel = 'linear')\n",
    "svc2.fit(x_train, y_train)\n",
    "prediction = svc2.predict(x_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df2.drop('age', axis=1, inplace=True)    # drop all individual features\n",
    "df2.drop('gender', axis=1, inplace=True)\n",
    "df2.drop('jundice', axis=1, inplace=True)\n",
    "df2.drop('austim', axis=1, inplace=True)\n",
    "df2.drop('used_app_before', axis=1, inplace=True)\n",
    "df2.drop('result', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df2.drop(['classification'], axis = 1)\n",
    "y = df2['classification']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5)  # create new training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "classes = [\"No\", \"Yes\"]\n",
    "for name, classifier in classifiers:  # loops through classifiers and applies same as above.\n",
    "    kfold = model_selection.KFold(n_splits=5)\n",
    "    result = model_selection.cross_val_score(classifier, x, y, cv=kfold, scoring='accuracy')\n",
    "    results.append(result)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    pred = classifier.predict(x_test)\n",
    "    print(name)\n",
    "    print('Accuracy Score: ', accuracy_score(y_test, pred))\n",
    "    print('Recall Score: ', recall_score(y_test, pred))\n",
    "    print('F1 Score: ', f1_score(y_test, pred))\n",
    "    print(classification_report(y_test, pred, target_names=classes))\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['LR', 'DT', 'RF', 'KNN', 'SVM']\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Classifier comparison')\n",
    "ax = fig.add_subplot(111) \n",
    "plt.boxplot(results)  # plot results\n",
    "ax.set_xticklabels(names)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
